%%%%%%%%%%%%%%%%%%%%%%%%%% example.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample input file for your contribution to Springer ENCYCLOPEDIAs
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%%%%%%%%%% Springer-Verlag %%%%%%%%%%%%%%%%%%%%%%%%%%


% RECOMMENDED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[natbib]{svcyclop}

% \documentclass[natbib]{svcyclop}
% call for the natbib-system if you wish to have sophisticated citations,
% remember to adapt the references at the end of your contribution then
% see explanation at the end of this file.
%
% A detailed explanation and demonstration of the natbib system can
% be found at
%     http://merkel.zoneo.net/Latex/natbib.php
%
% If you use BibTeX to manage your citation use the style "spbasic.bst"
% that is "natbib" aware.

\usepackage{graphicx}    % standard LaTeX graphics tool
                         % when including figure files

\usepackage{amsfonts,amsmath} % typesetting complicated math

% Hint:
% Use the "hyperref" package in the preamble
% if you want to supply active links within
% your text; e.g. at the \CrossRef section
% \usepackage{hyperref}

% Hint:
% Use the package "url" in the preamble
% to avoid problems with special characters
% used in your e-mail or web address in the
% \author or the \institute field below
\usepackage{url}
\urlstyle{tt}

\input{preamble}

\def\dist{{\sf dist}}


% etc.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

% Please specify your Entry Title in one continuous line
\title{Local reconstruction}

% Please specify the Names of Entry Author(s)
\author{C. Seshadhri\inst{1}}
% if there is more than one author, use "\and" in between
% the particular author lines
%
% add "\inst{<No.>}" directly after the author name to indicate
% the mapping to the relevant affiliations/addresses in the
% forthcoming "\institute" field
%
% see also the example contribution file "example.tex" for detailed info

% Please specify your Address/Affiliation and use "\\" as EOL for structuring
% specify Phone / Fax / e-mail if applicable, use "\\" as EOL for structuring
% more than one address/affiliation? separate each two entries with
% a line containing "\and"
\institute{
Sandia National Laboratories,
Livermore, CA, USA}
% make sure to give at least as many institute addresses
% as the mapping to the authors requires;
% the numbering is done automatically by the "\and" command
% see also the example contribution file "example.tex" for detailed info

% Please specify Years and Authors of Summarized Original Work
% use one continuous line for each paper; use semicolon to separate
% the year from the last names; don't use "and" between author names
% adhere to the following format:
% "Year of paper"; "last names of authors" separated by commas without "and"
% use "\\" as EOL for structuring
\sumoriwork{
2010; Saks, Seshadhri}
% see also the example contribution file "example.tex"
% for detailed information
%

% Please specify the Keywords - use semicolon for separation
\keywords{Property testing; sublinear algorithms; data reconstruction}

\maketitle  % completes, checks, and typesets the contribution's head

% you have 7 predefined headings at hand you can use throughout your contribution;
% just call the relevant commands instead of generating a new "\section" for them;
% the next two headings are mandatory:
% \ProbDef   -   Problem Definition
% \KeyRes    -   Key Results
%
% the following heading commands may be used as and when required:
% \Applic    -   Applications
% \OpenProb  -   Open Problems
% \ExpRes    -   Experimental Results
% \DataSets  -   URLs to Code and Data Sets
% \CrossRef  -   Cross References

\CrossRef

Testing if an array is sorted, monotonicity testing


\ProbDef

Consider some massive dataset represented as a function $f: D \mapsto R$,
where $D$ is discrete and $R$ is an arbitrary range.
This dataset could be as varied as an array of numbers, a graph, a matrix, or a high-dimensional function.
Datasets are often useful because they possess some 
property of interest. An array might be sorted, a graph might be 
connected, a matrix might be orthogonal, or a function might be convex. These properties are critical to the use
of the dataset. Yet, due to unavoidable errors (say, in storing the dataset), these
properties might not hold any longer. For example, a sorted array could become unsorted because of roundoff errors.

Can we find a function $g: D \mapsto R$ that satisfies the property and is ``sufficiently close"
to $f$? Let us formalize this question. Let $\cP$ denote a property, which we define as a subset
of functions. We define a \emph{distance} between functions, $\dist(f,g) = |\{x | f(x) \neq g(x)\}|/|D|$. In words, this is the fraction
of domain points where $f$ and $g$ differ (the relative Hamming distance). This definition naturally extends to properties:
$\dist(f,\cP) = \min_{h \in \cP} \dist(f,h)$. This is the minimum amount of change $f$ must undergo to have property $\cP$.
Our aim is to construct $g \in \cP$ such that $\dist(f,g)$ is ``small". The latter can be quantified
by comparing with the baseline, $\dist(f,\cP)$.


The \emph{offline reconstruction} problem involves explicitly constructing $g$ from $f$.
But this is prohibitively expensive if $f$ is a large dataset. Instead, we wish to \emph{locally} construct $g$,
meaning we want to quickly compute $g(x)$ (for $x \in D$) without constructing $g$ completely.

{\bf Local filters~\cite{SS06}:} A {\em local filter} for property ${\cal P}$
is an algorithm $A$ satisfying the following conditions. The filter 
has \emph{oracle access} to function $f:D \mapsto R$, meaning that it can 
access $f(x)$ for any $x \in D$. Each such access is called a \emph{lookup}.
The filter takes
as input an auxiliary random seed $\rho$ and $x \in D$.  
For fixed $f, \rho$, $A$ runs deterministically on input $x$ to produce an output $A_{f,\rho}(x)$.
Note that $A_{f,\rho}$ specifies a function on domain $D$, which will be the desired function $g$.

\begin{enumerate}
\item \label{prop:1} For each $f$ and $\rho$,  $A_{f,\rho}$ 
always satisfies $\mathcal{P}$. 
\item \label{prop:2} For each $f$, with high probability over $\rho$, the function $A_{f,\rho}$ is suitably
close to $f$.
\item \label{prop:3} For each $x$, $A_{f,\rho}(x)$ can be computed with very few lookups.
\item \label{prop:4} The size of the random seed $\rho$ should be much smaller than $D$.
\end{enumerate}

Let $g$ be $A_{f,\rho}$. Condition~\ref{prop:2} has been formalized in at least two different ways. The original definition demanded that $\dist(f,g) \leq c\cdot \dist(f,\cP)$,
where $c$ is a fixed constant~\cite{SS06}. Other results only enforce Condition~\ref{prop:2} when
$f \in \cP$~\cite{JhRa13,AwJh+12}. One could imagine desiring $|\dist(f,g) - \dist(f,\cP)| < \delta$,
for input parameter $\delta$.
%
%Sometimes, we require this only when $\dist(f,\cP)$ is extremely small (or even zero). 
Conditions~\ref{prop:3} and~\ref{prop:4} typically demand that the lookup complexity and random
seed lengths are $o(|D|)$ (sometimes we desire them to be $\poly(\log |D|)$ or even constant). 


%
%
%in an \emph{online} manner. Suppose $f$ is a sorted array of numbers on which we wish to perform
%binary search. Because of various errors, $f$ is not sorted, so we instead would need to 
%perform the search on a sorted array $g$ (that is close to $f$). To perform binary search, we only
%need query access to $g$, which does not require constructing $g$ all at once.
%%These considerations motivated the \emph{online reconstruction model} of~\cite{ACCL}.


\subsection{Connections with other models}


The notion of reconstruction through filters was first proposed by Ailon et al in~\cite{ACCL2},
though the requirements were less stringent. There is a sequence $x_1, x_2, \ldots$ of domain points generated
online. Given $x_i$, the filter outputs value $g(x_i)$. 
The filter is allowed to store previous outputs to ensure consistency. 
Saks and Seshadhri~\cite{SS06} defined local filters to address two concerns with this model.
First, the storage of all previous queries and answers is a massive space overhead. Second,
different runs of the filter construct different $g$'s (because the filter is randomized).
So we cannot instantiate multiple copies of the filter to handle queries independently and consistently.

Independent of this line of work, Brakerski defined \emph{local restorers}~\cite{Br08}, which are basically
equivalent to filters with an appropriate setting of Conditions~\ref{prop:1} and~\ref{prop:2}.
A major generalization of local filters, called \emph{local computation algorithms}, was subsequently proposed
by Rubinfeld et al~\cite{RuTaVa+11}. This model considers computation on a large input where the output itself
is large. (For example, one may want a maximal independent set of a massive graph.) 
The aim is to locally compute the output, by an algorithm akin to a filter.

Depending on how Property~\ref{prop:2} is instantiated, filters
can easily be used for tolerant testing and distance approximation~\cite{PRR04}. If the filter ensures
that $\dist(f,g)$ is comparable to $\dist(f,\cP)$, then it suffices to estimate $\dist(f,g)$
for distance approximation. 
%
%Given $f$,
%we wish to get an approximation of $\dist(f,\cP)$ in sublinear time (or given $\eps$, just tell if $\dist(f,\cP) > \eps$).
%Because of Property~\ref{prop:2}, it suffices to just estimate $\dist(f,A_{f,\rho})$ to approximate $\dist(f,\cP)$.

A special case of local reconstruction that has received extensive attention is decoding of error correcting codes. 
Here, $f$ is some string, and $\cP$ is the set of all valid codewords. 
In local decoding there is either \emph{one} correct output, or 
a sparse list of possible correct outputs. For general properties,
there may be many (possibly infinitely many) ways
to construct a valid reconstruction $g$. This creates challenges
for designing filters. Once the random seed is fixed, all query answers
provided by the filter must be consistent with a {\em single} function
having the property.



\KeyRes

Over the past decade, there have been numerous results on local reconstruction,
over a variety of domains. 

{\bf Monotonicity:} The most studied property for local reconstruction
is monotonicity~\cite{ACCL2,SS06,BhGr+12,AwJh+12}. Consider $f:[n]^d \mapsto \RR$,
where $d,n$ are positive integers are $[n] = \{1,2,\ldots,n\}$. The domain
is equipped with the natural coordinate-wise partial order. Namely, $x \prec y$
if $x \neq y$ and all coordinates of $x$ are less than or equal those of $y$. A function $f$
is monotone if: $\forall x \prec y$, $f(x) \leq f(y)$. When $d=1$,
monotone functions are exactly sorted arrays.

Most initial work on local filters focused exclusively on monotonicity.
There exists a filter of running
time $(\log n)^{O(d)}$ with $\dist(f,g) \leq 2^{O(d)}\dist(f,\cP)$~\cite{SS06}.
There are nearly matching lower bounds that are extremely strong; even for relaxed versions of Condition~\ref{prop:2}~\cite{AwJh+12}.

{\bf Lipschitz continuity:} Let $n,d$ be positive integers and $c$ be a positive real number. A function $f:[n]^d \mapsto \RR$ is $c$-Lipschitz
if $\forall x,y$, $|f(x) - f(y)| \leq c\|x-y\|_1$. This is a fundamental property
of functions and appears in functional analysis, statistics, and optimization.
Recently, Lipschitz continuity was studied from a property testing perspective by Jha and Raskhodnikova~\cite{JhRa13}.
Most relevant to this essay, they gave an application of local Lipschitz filters
for differential privacy. The guarantees on their filter are analogous to monotonicity
(with a weaker form of Property~\ref{prop:2}). Awasthi, Jha, Molinaro, and Raskhodnikova~\cite{AwJh+12}
gave matching lower bounds for these reconstruction problems.
%
%Again, matching upper and lower bounds
%are known~\cite{JhRa13,AwJh+12}.

{\bf Dense graph properties:} Dense graphs are commonly studied in property testing, where
the input is given as a binary adjacency matrix. Brakerski's work on local restorers provides
filters for bipartiteness and existence of large cliques. Large classes of dense graphs are known
to be tolerant testable. These results have been extended to local filters
for hypergraph properties by Austin and Tao~\cite{AT09}. This work was developed independently
of all the previous work on filters, and their algorithms are called ``repair"
algorithms.

{\bf Connectivity properties of sparse graphs:} In the sparse graph setting, the input $G$
is an adjacency list of a bounded degree graph. Filters have been given for several properties regarding connectivity.
Campagna, Guo, and Rubinfeld~\cite{CaGuRu13} provide reconstructors for $k$-connectivity and the property
of having low diameter.
%Another connectivity property of great interest is that of \emph{expansion}.
%Roughly speaking, a bounded-degree expander has the property that for any subset $S$ of at most half the vertices, there
%are at least $\Omega(|S|)$ edges leaving $S$.
Local reconstructors for the property of expansion were given by Kale and Seshadhri~\cite{KalS11-j}.

{\bf Convexity in 2,3-dimensions:} 
Chazelle and Seshadhri~\cite{ChSe11-j} studied reconstruction in the geometric setting. They focus
on convex polygon and 3D convex polytope reconstruction. These results were in the online filter
setting of~\cite{ACCL2}, though their 3D result is a local filter. 

\OpenProb

For any property tester, one can ask if the associated property has a local filter.
Given the breadth of this area, we cannot hope to give a good summary of open problems. Nonetheless,
we make a few suggestions.

{\bf The curse of dimensionality for monotonicity and Lipschitz:} Much work has gone into understanding local filters
for monotonicity, but it is not clear how to remove the exponential dependence on $d$.
Can we find a reasonable setting for filters where a $\poly(d,\log n)$ lookup complexity is possible? One possibility is requiring only ``additive error" in Condition~\ref{prop:2}.
For some parameter $\delta > 0$, we only want $|\dist(f,g) - \dist(f,\cP)| \leq \delta$. Is there a filter
with lookup complexity $\poly(d,\log n,1/\delta)$? This definition would avoid previous lower bounds~\cite{AwJh+12}.
%
%
%The lower bound of $(\log n)^{\Omega(d)}$ uses a specific form for Property~\ref{prop:2}~\cite{AwJh+12}.
%All these forms require when $f$ is monotone, $\dist(f,g)$ must be zero. (There is one exception, where the filter is allowed
%bounded perturbations, but the lower bound remains~\cite{AwJh+12}.) 

{\bf Filters for convexity:} Filters for convexity could have a great impact on optimization.
A local filter would implicitly represent a close enough convex function to an input non-convex function,
which would be extremely useful for (say) minimization. For this application, it would be essential
to handle high-dimensional functions. Unfortunately, there are no known property testers for convexity in this setting,
so designing local filters is a distant goal.

{\bf Filters for properties of bounded-degree graphs:} The large class of minor-closed properties (such as planarity)
is known to be testable for bounded-degree graphs~\cite{BSS08}. Can we get local filters for these properties? This appears to 
be a challenging question, since even approximating the distance to planarity is a difficult problem.
Nonetheless, the right relaxations of filter conditions could lead to positive results for filters.

%% BibTeX users please use
\bibliographystyle{spbasic}
\bibliography{filter-survey}
%\end{document}
%
% Non-BibTeX users please use
%\begin{thebibliography}{8.}
%
% and use \bibitem to create references.
%
% Use the following syntax and markup for your references
%


%% Complete Book
%\bibitem{book} Faber K (1997) Biotransformations in organic
%chemistry, 3rd edn. Springer, Berlin Heidelberg New York
%
%% Contributions, Chapters or Sections in Books
%\bibitem{contribution} Brown FR, Jackson D (1987) Analytical chemistry.
%In: Whie FC, Red SA (eds) Modern chemistry. Springer, Berlin Heidelberg
%New York, p 220
%
%% Journal
%\bibitem{journal}
%Fuchigami T (1994) Top Curr Chem 170:25
%
%% Other Possibilities
%\bibitem{Other} Tanzawa H (1986) First Japan-US workshop on Biomedical
%Polymer Science. Kyoto, Japan
%
%\end{thebibliography}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\end{document}

% here a faked reference section follows working with the natbib-system
% allowing for author-year citation without automated BibTeX usage

% Non-BibTeX users please use

%\begin{thebibliography}{12}
%%
%% and use \bibitem to create references. Consult the Instructions
%% for authors for reference list style.
%
%\bibitem[{{Alpert} et~al.(1998){Alpert}, {Chan}, {Kahng}, {Markov},
%{Mulet}}]{AlpChKaMaMu98} {Alpert} CJ,
%{Chan} T, {Kahng} AB, {Markov} IL, {Mulet} P (1998) Faster
%minimization of linear wirelength for global placement. IEEE
%Trans. CAD 17(1), 3-13
%
%\bibitem[{{Caldwell} et~al.(2000){Caldwell}, {Kahng},
%{Markov}}]{CalKahMar00} {Caldwell} AE, {Kahng} AB, {Markov} IL (2000)
%Optimal partitioners and end-case placers for standard-cell layout.
%IEEE Trans. CAD 19(11), 1304-1314
%
%\bibitem[{{Chan} et~al.(2005){Chan}, {Cong}, {Sze}}]{ChaConSze05}
%{Chan} T, {Cong} J, {Sze} K (2005) Multilevel generalized force-directed
%method for circuit placement. Proc. Intl. Symp. Physical Design.
%ACM Press, San Francisco, 3-5 Apr 2005. pp. 185-192
%
%\bibitem[{{Ausiello} et~al.(1998)
%{Ausiello}, {Crescenzi}, {Gambosi}, {Kann}, {Marchetti-Spaccamela},
%{Protasi}}] {CGKMSP98} {Ausiello} G, {Crescenzi} P, {Gambosi} G,
%{Kann} V, {Marchetti-Spaccamela} A, {Protasi} M (1998) Complexity and
%Approximation: Combinatorial optimization problems and their
%approximability properties. Springer
%
%\bibitem[{{Hu} et~al.(2005){Hu}, {Marek-Sadowska}}]{HuMar05}
%{Hu} B, {Marek-Sadowska} M (2005) Multilevel fixed-point-additionbased
%VLSI placement. IEEE Trans. CAD 24(8), 1188-1203
%
%\bibitem[{{Kahng} et~al.(2005){Khang}, {Wang}}]{KhaWan05}
%{Kahng} AB, {Wang} Q (2005) Implementation and extensibility of an
%analytic placer. IEEE Trans. CAD 24(5), 734-747
%
%\bibitem[{{Kennings} et~al.(2002){Kennings}, {Markov}}]{KenMar02}
%{Kennings} A, {Markov} IL (2002) Smoothingmax-terms and analytical
%minimization of half-perimeter wirelength. VLSI Design 14(3),
%229-237
%
%\bibitem[{{Kennings} et~al.(2006){Kennings}, {Vorwerk}}]{KenVor06}
%{Kennings} A, {Vorwerk} K (2006) Force-directed methods for generic
%placement. IEEE Trans. CAD 25(10), 2076-2087
%
%\bibitem[{{Papa} et~al.(2007){Papa}, {Markov}}]{PapMar07}
%{Papa} DA, {Markov} IL (2007) Hypergraph partitioning and clustering.
%In: Gonzalez, T. (ed.) Handbook of algorithms. Taylor \&
%Francis Group, Boca Raton, CRC Press, pp. 61-1
%
%\bibitem[{{Reda} et~al.(2006){Reda}, {Chowdhary}}]{RedCho06} {Reda} S,
%{Chowdhary} A (2006) Effective linear programming based
%placement methods. In: ACM Press, San Jose, 9-12 Apr
%
%\bibitem[{{Roy} et~al.(2006){Roy}, {Adya}, {Papa}, {Markov}}]{RoyAdyPapMar06}
%{Roy} JA, {Adya} SN, {Papa} DA, {Markov} IL(2006) Min-cut floorplacement.
%IEEE Trans. CAD 25(7), 1313-1326
%
%\bibitem[{{Tang} et~al.(2005){Tang}, {Tian}, {Wong}}]{TanTiaWon05}
%{Tang} X, {Tian} R, {Wong} MDF (2005) Optimal redistribution of white
%space for wirelength minimization. In: Tang, T.-A. (ed.) Proc.
%Asia South Pac. Design Autom. Conf., ACM Press, 18-21 Jan
%2005, Shanghai. pp. 412-417
%
%\end{thebibliography}
%
\end{document}
% end of file "example.tex"


